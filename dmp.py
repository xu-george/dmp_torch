"""
A pytorch version of trainable DMPs
"""
import numpy as np
import torch
import torch.nn as nn

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


class CanonicalSystem:
    """
    Canonical system, shared by all DMPs
    """
    def __init__(self, dt=0.01, ax=1.0, device='cpu'):
        """
        :param dt: the timestep
        :param ax: a gain term on the dynamical system
        :param device:
        """
        self.ax = ax
        self.dt = dt
        self.run_time = 1.0
        self.timesteps = int(self.run_time / self.dt)
        self.device = device

    def reset_state(self):
        """Reset the system state"""
        self.x = 1.0

    def step(self, error_coupling=1.0):
        """
        Decaying from 1 to 0 according to dx = -ax*x.
        tau float: gain on execution time. increase tau to make the system execute faster
        error_coupling float: slow down if the error is > 1
        """
        self.x += (-self.ax * self.x * error_coupling) * self.dt
        return self.x

    def rollout(self, error_coupling=1.0):
        """
        Generate x for open loop movements.
        """
        self.x_track = torch.zeros(self.timesteps).to(self.device)
        self.reset_state()
        for t in range(self.timesteps):
            self.x_track[t] = self.x
            self.step(error_coupling)
        return self.x_track.to(self.device)


class DMPCore(nn.Module):
    """
    Core part about DMP.
    """
    def __init__(self, n_bfs, cs, dt=0.01, run_time=1, ay=None,
                 by=None, w=None, device='cpu'):
        super(DMPCore, self).__init__()

        self.device = device
        self.n_bfs = n_bfs
        self.run_time = run_time
        self.dt = dt
        self.cs = cs   # canonical system

        # define the default initial and goal state
        self.y0 = 0.0
        self.goal = 1.0

        # define the attractor system
        self.ay = 25.0 if ay is None else ay  # Schaal 2012
        self.by = self.ay / 4.0 if by is None else by  # Schaal 2012

        # define the force system
        if w is None:
            self.w = torch.zeros(n_bfs).to(device)
        else:
            self.w = w

        # define centers, widths of the basis functions
        des_c = torch.linspace(0, self.run_time, self.n_bfs).to(self.device)
        self.c = torch.exp(-self.cs.ax * des_c)
        self.h = torch.ones(self.n_bfs) * self.n_bfs ** 1.5 / self.c / self.cs.ax

    def reset(self):
        """Reset the system state"""
        self.y = self.y0
        self.dy = 0.0
        self.ddy = 0.0
        self.cs.reset_state()

    def gen_goal_initial(self, path):
        y0 = path[0]
        goal = path[-1]
        return y0, goal

    def gen_psi(self, x):
        """Generates the activity of the basis functions for a given
        canonical system rollout.

        x float, array: the canonical system state or path
        """
        if isinstance(x, torch.Tensor):
            x = x.unsqueeze(1)
        return torch.exp(-self.h * (x - self.c) ** 2)

    def gen_target_force(self, path):
        """
        generate the desired force in the attractor system
        :param path:
        :return:
        """
        y = path.detach()   # a copy of the path
        dy = torch.gradient(y)[0] / self.dt
        ddy = torch.gradient(dy)[0] / self.dt
        f_target = ddy - self.ay * (self.by * (self.goal - y) - dy)
        return f_target

    def gen_force(self):
        """
        The force generated by the DMP basic function
        """
        x_track = self.cs.rollout()
        psi_track = self.gen_psi(x_track)  # get the basis function activations

        f = torch.matmul(psi_track, self.w.unsqueeze(1)).squeeze(1) * x_track * (self.goal - self.y0)
        sum_psi = torch.sum(psi_track, dim=1)
        return f / sum_psi

    def step(self, x, tau=1.0, error=0.0, external_force=None):
        """Generate the next step of the DMP.
        :param tau:
        :param error:
        :return:
        """
        error_coupling = 1.0 / (1.0 + error)
        x = x
        psi = self.gen_psi(x)

        # calcualte the apply force to the attractor system
        front_term = x * (self.goal - self.y0)
        f = front_term * torch.dot(psi, self.w)
        sum_psi = torch.sum(psi)
        if torch.abs(sum_psi) > 1e-6:
            f /= sum_psi

        self.ddy = f + self.ay * (self.by * (self.goal - self.y) - self.dy)
        if external_force is not None:
            self.ddy += external_force
        self.dy += self.ddy * tau * self.dt * error_coupling
        self.y += self.dy * tau * self.dt * error_coupling

        return self.y, self.dy, self.ddy

    def rollout(self, y0, goal):
        """
        Generate step by step output.
        """
        self.y0 = y0
        self.goal = goal

        self.reset()
        y_track = torch.zeros(self.cs.timesteps)
        dy_track = torch.zeros(self.cs.timesteps)
        ddy_track = torch.zeros(self.cs.timesteps)
        for t in range(self.cs.timesteps):
            x = self.cs.step(error_coupling=1)
            y_track[t], dy_track[t], ddy_track[t] = self.step(x=x, error=0)
        return y_track.detach().numpy(), dy_track.detach().numpy(), ddy_track.detach().numpy()


class SingleDMP(DMPCore):
    """
    DMP with a one DOF, weight are obtained by analytical solution
    The code can generate the desired trajectory in two ways:
    1. generate the desired trajectory step by step --  rollout()
    """
    def __init__(self, n_bfs, cs, dt=0.01, ay=None,
                 by=None, run_time=1, w=None, device='cpu'):
        """
        current version the centre is fixed
        :param n_bfs: number of basis functions
        :param dt: timestep for simulation
        :param ay: a gain term on the forcing term
        :param by: a gain term on the forcing term
        :param w: weights for the basis functions
        :param device:
        """
        super(SingleDMP, self).__init__(n_bfs=n_bfs, cs=cs, dt=dt, ay=ay, by=by,
                                        run_time=run_time, w=w, device=device)

    def gen_weights(self, f_target):
        """
        Generate a set of weights over the basis functions such that the target forcing term trajectory is matched.
        f_target np.array: the desired forcing term trajectory
        """
        x_track = self.cs.rollout()
        psi_track = self.gen_psi(x_track)  # get the basis function activations

        k = self.goal - self.y0

        for b in range(self.n_bfs):
            numer = torch.sum(x_track * psi_track[:, b] * f_target)
            denom = torch.sum(x_track ** 2 * psi_track[:, b])
            self.w[b] = numer / denom
            if abs(k) > 1e-5:
                self.w[b] /= k

    def imitate_path(self, path):
        """Imitate a given path.
        path np.array: the desired path to imitate
        """
        if isinstance(path, np.ndarray):
            path = torch.from_numpy(path).to(self.device)
        self.y0, self.goal = self.gen_goal_initial(path)
        f_target = self.gen_target_force(path)
        self.gen_weights(f_target)
        self.reset()


class TrainSingleDMP(DMPCore):
    """
    the weight of DMP are trained by using the gradient descent
    """
    def __init__(self, n_bfs, cs, dt=0.01, ay=None, by=None, run_time=1, w=None, device='cpu'):
        super(TrainSingleDMP, self).__init__(n_bfs=n_bfs, cs=cs, dt=dt, ay=ay, by=by,
                                             run_time=run_time, w=w, device=device)
        # define the trainable parameters
        self.w = torch.nn.Parameter(self.w)
        self.h = torch.nn.Parameter(self.h)

    def MSE_loss(self, path):
        if isinstance(path, np.ndarray):
            path = torch.from_numpy(path).to(self.device)
        self.y0, self.goal = self.gen_goal_initial(path)
        f_target = self.gen_target_force(path)
        # generate the force
        f_gen = self.gen_force()
        return torch.mean((f_gen - f_target) ** 2)

    def train_dmp(self, optimizer, path, epoch=1000):
        """
        :param optimizer:
        :param path:
        :param epoch:
        :return:
        """
        for i in range(epoch):
            optimizer.zero_grad()
            loss = self.MSE_loss(path)
            loss.backward()
            optimizer.step()

            # print the loss every 100 epoch
            if (i+1) % 200 == 0:
                print('epoch: {}, loss: {}'.format(i, loss.item()))


class TrainDMPs(nn.Module):
    """
    Train a set of DMPs with a given set of paths.
    """
    def __init__(self, n_dof, n_bfs, dt=0.01, ay=None, by=None, run_time=1, w=None, device='cpu'):
        """
        :param n_dof: number of degrees of freedom
        :param n_bfs: a list of number of basis functions for each DOF
        :param cs: canonical system
        :param dt: timestep for simulation
        :param ay:
        :param by:
        :param run_time:
        :param w:
        :param device:
        """
        super(TrainDMPs, self).__init__()
        self.dt = dt
        self.n_dof = n_dof
        self.device = device
        self.run_time = run_time
        self.w = w

        self.ay = 25.0 if ay is None else ay  # Schaal 2012
        self.by = self.ay / 4.0 if by is None else by  # Schaal 2012

        if isinstance(n_bfs, int):
            n_bfs = [n_bfs] * n_dof

        self.cs = CanonicalSystem(dt=0.01)

        self.DMPs = nn.ModuleList()
        for i in range(self.n_dof):
            self.DMPs.append(TrainSingleDMP(n_bfs=n_bfs[i], cs=self.cs, ay=self.ay, by=self.by, device=self.device))

    def total_MSE_loss(self, path):
        """
        get total loss for each dmp
        :return:
        """
        loss = torch.zeros(self.n_dof)
        for i in range(self.n_dof):
            loss[i] = self.DMPs[i].MSE_loss(path[:, i])
        return torch.sum(loss)

    def dmps_train(self, optimizer, path, epoch=1000):
        """
        :param optimizer:
        :param path:
        :param epoch:
        """
        for i in range(epoch):
            optimizer.zero_grad()
            loss = self.total_MSE_loss(path)
            loss.backward()
            optimizer.step()

            # print the loss every 100 epoch
            if (i+1) % 200 == 0:
                print('epoch: {}, loss: {}'.format(i, loss.item()))

    def rollout(self, y0, goal):
        """
        generate new trajectory
        :return:
        """
        assert len(y0) == self.n_dof and len(goal) == self.n_dof

        self.y0 = y0
        self.goal = goal

        y_track = np.zeros((self.cs.timesteps, self.n_dof))
        dy_track = np.zeros((self.cs.timesteps, self.n_dof))
        ddy_track = np.zeros((self.cs.timesteps, self.n_dof))

        for i in range(self.n_dof):
            y_track[:, i], dy_track[:, i], ddy_track[:, i] = self.DMPs[i].rollout(self.y0[i], self.goal[i])
        return y_track, dy_track, ddy_track




